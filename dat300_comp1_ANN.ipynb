{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of determination (R^2) for regression\n",
    "def r_square(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def r_square_loss(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x_train = pd.read_csv(\"./dat300-h2020-ca1/X_train.csv\")\n",
    "x_test = pd.read_csv(\"./dat300-h2020-ca1/X_test.csv\")\n",
    "y_train = pd.read_csv(\"./dat300-h2020-ca1/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show columns with lots of zeros\n",
    "#x_train = x_train.replace(0.0, np.nan)\n",
    "#missing_values = x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with lots of zeros\n",
    "#x_train = x_train.drop(columns=[\"Blast Furnace Slag (component 2)(kg in a m^3 mixture)\",\n",
    "#                               \"Fly Ash (component 3)(kg in a m^3 mixture)\",\n",
    "#                               \"Superplasticizer (component 5)(kg in a m^3 mixture)\"])\n",
    "\n",
    "#x_test = x_test.drop(columns=[\"Blast Furnace Slag (component 2)(kg in a m^3 mixture)\",\n",
    "#                               \"Fly Ash (component 3)(kg in a m^3 mixture)\",\n",
    "#                               \"Superplasticizer (component 5)(kg in a m^3 mixture)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 8)\n",
      "Observations BEFORE removing outliers: (618, 8)\n",
      "(569, 8)\n",
      "Observations AFTER removing outliers: (569, 8)\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "print(x_train.shape)\n",
    "Q1 = x_train.quantile(0.25)\n",
    "Q3 = x_train.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "mask = ((x_train < (Q1 - 1.5 * IQR)) | (x_train > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "print(\"Observations BEFORE removing outliers:\", x_train.shape)\n",
    "x_train = x_train[~mask]\n",
    "print(x_train.shape)\n",
    "y_train = y_train[~mask]\n",
    "# X = X.values\n",
    "# _test = x_test.values\n",
    "print(\"Observations AFTER removing outliers:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOXPLOT\n",
    "a = x_train.plot(kind=\"box\", subplots=True, figsize=(12, 12), layout=(5,4), sharex=False, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras ANN\n",
    "#model.add(BatchNormalization())\n",
    "sample_vector_length = x_train.shape[1]\n",
    "model = Sequential([ \n",
    "                   Dense(200, activation=\"relu\", input_shape=(sample_vector_length,)),\n",
    "                   Dense(100, activation=\"relu\"),\n",
    "                   Dense(100, activation=\"relu\"),\n",
    "                   Dense(1)])\n",
    "model.compile(optimizer=tensorflow.keras.optimizers.Nadam(),\n",
    "             loss=,\n",
    "             metrics=[r_square])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 5.4275 - r_square: -4.5045 - val_loss: 4.7849 - val_r_square: -3.9595\n",
      "Epoch 2/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.3667 - r_square: -1.2888 - val_loss: 0.8229 - val_r_square: 0.1895\n",
      "Epoch 3/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6604 - r_square: 0.3411 - val_loss: 0.6398 - val_r_square: 0.3935\n",
      "Epoch 4/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5757 - r_square: 0.4133 - val_loss: 0.6240 - val_r_square: 0.4095\n",
      "Epoch 5/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5023 - r_square: 0.4996 - val_loss: 0.5883 - val_r_square: 0.4374\n",
      "Epoch 6/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4795 - r_square: 0.5241 - val_loss: 0.5694 - val_r_square: 0.4584\n",
      "Epoch 7/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5015 - r_square: 0.4287 - val_loss: 0.7113 - val_r_square: 0.2968\n",
      "Epoch 8/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5162 - r_square: 0.5033 - val_loss: 0.5378 - val_r_square: 0.4879\n",
      "Epoch 9/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4389 - r_square: 0.5640 - val_loss: 0.5169 - val_r_square: 0.5099\n",
      "Epoch 10/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4012 - r_square: 0.6145 - val_loss: 0.4978 - val_r_square: 0.5277\n",
      "Epoch 11/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3897 - r_square: 0.6126 - val_loss: 0.4801 - val_r_square: 0.5447\n",
      "Epoch 12/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4044 - r_square: 0.6061 - val_loss: 0.4727 - val_r_square: 0.5488\n",
      "Epoch 13/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3891 - r_square: 0.6119 - val_loss: 0.4555 - val_r_square: 0.5628\n",
      "Epoch 14/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3932 - r_square: 0.4913 - val_loss: 0.4467 - val_r_square: 0.5740\n",
      "Epoch 15/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3648 - r_square: 0.6404 - val_loss: 0.4331 - val_r_square: 0.5783\n",
      "Epoch 16/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3737 - r_square: 0.5845 - val_loss: 0.3909 - val_r_square: 0.6298\n",
      "Epoch 17/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3233 - r_square: 0.6759 - val_loss: 0.3827 - val_r_square: 0.6397\n",
      "Epoch 18/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3216 - r_square: 0.6530 - val_loss: 0.3783 - val_r_square: 0.6415\n",
      "Epoch 19/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3226 - r_square: 0.6561 - val_loss: 0.4411 - val_r_square: 0.5815\n",
      "Epoch 20/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2949 - r_square: 0.6905 - val_loss: 0.4958 - val_r_square: 0.5051\n",
      "Epoch 21/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3124 - r_square: 0.6291 - val_loss: 0.3703 - val_r_square: 0.6382\n",
      "Epoch 22/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2674 - r_square: 0.7306 - val_loss: 0.3201 - val_r_square: 0.6959\n",
      "Epoch 23/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2395 - r_square: 0.7570 - val_loss: 0.2826 - val_r_square: 0.7295\n",
      "Epoch 24/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2204 - r_square: 0.7736 - val_loss: 0.2674 - val_r_square: 0.7479\n",
      "Epoch 25/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2046 - r_square: 0.7950 - val_loss: 0.2730 - val_r_square: 0.7365\n",
      "Epoch 26/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2004 - r_square: 0.8051 - val_loss: 0.2256 - val_r_square: 0.7837\n",
      "Epoch 27/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1832 - r_square: 0.8121 - val_loss: 0.2360 - val_r_square: 0.7757\n",
      "Epoch 28/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1742 - r_square: 0.7856 - val_loss: 0.2584 - val_r_square: 0.7351\n",
      "Epoch 29/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1752 - r_square: 0.8304 - val_loss: 0.1957 - val_r_square: 0.8086\n",
      "Epoch 30/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1488 - r_square: 0.8564 - val_loss: 0.2009 - val_r_square: 0.8044\n",
      "Epoch 31/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1568 - r_square: 0.8247 - val_loss: 0.2333 - val_r_square: 0.7597\n",
      "Epoch 32/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1467 - r_square: 0.8552 - val_loss: 0.1838 - val_r_square: 0.8190\n",
      "Epoch 33/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1261 - r_square: 0.8760 - val_loss: 0.1804 - val_r_square: 0.8233\n",
      "Epoch 34/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1343 - r_square: 0.8536 - val_loss: 0.5469 - val_r_square: 0.4674\n",
      "Epoch 35/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1891 - r_square: 0.8173 - val_loss: 0.1588 - val_r_square: 0.8444\n",
      "Epoch 36/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1211 - r_square: 0.8816 - val_loss: 0.1688 - val_r_square: 0.8311\n",
      "Epoch 37/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1161 - r_square: 0.8836 - val_loss: 0.1566 - val_r_square: 0.8481\n",
      "Epoch 38/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1200 - r_square: 0.8794 - val_loss: 0.1384 - val_r_square: 0.8606\n",
      "Epoch 39/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1101 - r_square: 0.8895 - val_loss: 0.1656 - val_r_square: 0.8381\n",
      "Epoch 40/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1210 - r_square: 0.8632 - val_loss: 0.2587 - val_r_square: 0.7301\n",
      "Epoch 41/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1149 - r_square: 0.8857 - val_loss: 0.1523 - val_r_square: 0.8460\n",
      "Epoch 42/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1115 - r_square: 0.8800 - val_loss: 0.2422 - val_r_square: 0.7540\n",
      "Epoch 43/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1158 - r_square: 0.8837 - val_loss: 0.1451 - val_r_square: 0.8495\n",
      "Epoch 44/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1131 - r_square: 0.8900 - val_loss: 0.1639 - val_r_square: 0.8316\n",
      "Epoch 45/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1031 - r_square: 0.8941 - val_loss: 0.2516 - val_r_square: 0.7357\n",
      "Epoch 46/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1055 - r_square: 0.8828 - val_loss: 0.6932 - val_r_square: 0.3118\n",
      "Epoch 47/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1531 - r_square: 0.8433 - val_loss: 0.2075 - val_r_square: 0.7793\n",
      "Epoch 48/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1078 - r_square: 0.8946 - val_loss: 0.1538 - val_r_square: 0.8376\n",
      "Epoch 49/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0923 - r_square: 0.9027 - val_loss: 0.1427 - val_r_square: 0.8501\n",
      "Epoch 50/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0903 - r_square: 0.8980 - val_loss: 0.2640 - val_r_square: 0.7243\n",
      "Epoch 51/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1017 - r_square: 0.9013 - val_loss: 0.1212 - val_r_square: 0.8754\n",
      "Epoch 52/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0945 - r_square: 0.9089 - val_loss: 0.1390 - val_r_square: 0.8563\n",
      "Epoch 53/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0850 - r_square: 0.9108 - val_loss: 0.1778 - val_r_square: 0.8102\n",
      "Epoch 54/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1030 - r_square: 0.8572 - val_loss: 0.9033 - val_r_square: 0.0672\n",
      "Epoch 55/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3995 - r_square: 0.6057 - val_loss: 0.3034 - val_r_square: 0.6914\n",
      "Epoch 56/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1201 - r_square: 0.8749 - val_loss: 0.1548 - val_r_square: 0.8471\n",
      "Epoch 57/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0920 - r_square: 0.9078 - val_loss: 0.1299 - val_r_square: 0.8680\n",
      "Epoch 58/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0895 - r_square: 0.9117 - val_loss: 0.1319 - val_r_square: 0.8666\n",
      "Epoch 59/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0816 - r_square: 0.9214 - val_loss: 0.1275 - val_r_square: 0.8690\n",
      "Epoch 60/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0852 - r_square: 0.9176 - val_loss: 0.1245 - val_r_square: 0.8713\n",
      "Epoch 61/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0796 - r_square: 0.9189 - val_loss: 0.1757 - val_r_square: 0.8126\n",
      "Epoch 62/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0848 - r_square: 0.9154 - val_loss: 0.1371 - val_r_square: 0.8606\n",
      "Epoch 63/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0839 - r_square: 0.9168 - val_loss: 0.1358 - val_r_square: 0.8578\n",
      "Epoch 64/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0775 - r_square: 0.9235 - val_loss: 0.1211 - val_r_square: 0.8748\n",
      "Epoch 65/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0810 - r_square: 0.8941 - val_loss: 0.3624 - val_r_square: 0.6160\n",
      "Epoch 66/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0970 - r_square: 0.9057 - val_loss: 0.1805 - val_r_square: 0.8038\n",
      "Epoch 67/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0797 - r_square: 0.9196 - val_loss: 0.1495 - val_r_square: 0.8368\n",
      "Epoch 68/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0764 - r_square: 0.9226 - val_loss: 0.1675 - val_r_square: 0.8181\n",
      "Epoch 69/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0760 - r_square: 0.9222 - val_loss: 0.1958 - val_r_square: 0.7946\n",
      "Epoch 70/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0866 - r_square: 0.9159 - val_loss: 0.1253 - val_r_square: 0.8692\n",
      "Epoch 71/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0668 - r_square: 0.9345 - val_loss: 0.1295 - val_r_square: 0.8645\n",
      "Epoch 72/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0732 - r_square: 0.9264 - val_loss: 0.1210 - val_r_square: 0.8752\n",
      "Epoch 73/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0734 - r_square: 0.9190 - val_loss: 0.1932 - val_r_square: 0.8051\n",
      "Epoch 74/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0752 - r_square: 0.9269 - val_loss: 0.1151 - val_r_square: 0.8806\n",
      "Epoch 75/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0690 - r_square: 0.9165 - val_loss: 0.5757 - val_r_square: 0.3884\n",
      "Epoch 76/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1096 - r_square: 0.8932 - val_loss: 0.1159 - val_r_square: 0.8776\n",
      "Epoch 77/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0658 - r_square: 0.9299 - val_loss: 0.1219 - val_r_square: 0.8750\n",
      "Epoch 78/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0664 - r_square: 0.9336 - val_loss: 0.1211 - val_r_square: 0.8746\n",
      "Epoch 79/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0647 - r_square: 0.9354 - val_loss: 0.1497 - val_r_square: 0.8442\n",
      "Epoch 80/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0652 - r_square: 0.9371 - val_loss: 0.1163 - val_r_square: 0.8780\n",
      "Epoch 81/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0650 - r_square: 0.9333 - val_loss: 0.2218 - val_r_square: 0.7559\n",
      "Epoch 82/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0770 - r_square: 0.9239 - val_loss: 0.1146 - val_r_square: 0.8799\n",
      "Epoch 83/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0651 - r_square: 0.9349 - val_loss: 0.1325 - val_r_square: 0.8561\n",
      "Epoch 84/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0594 - r_square: 0.9339 - val_loss: 0.1249 - val_r_square: 0.8725\n",
      "Epoch 85/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0692 - r_square: 0.9264 - val_loss: 0.1876 - val_r_square: 0.7959\n",
      "Epoch 86/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0653 - r_square: 0.9335 - val_loss: 0.1201 - val_r_square: 0.8767\n",
      "Epoch 87/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0609 - r_square: 0.9392 - val_loss: 0.1139 - val_r_square: 0.8818\n",
      "Epoch 88/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0630 - r_square: 0.9294 - val_loss: 0.2012 - val_r_square: 0.7931\n",
      "Epoch 89/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0732 - r_square: 0.9295 - val_loss: 0.1249 - val_r_square: 0.8665\n",
      "Epoch 90/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0664 - r_square: 0.9358 - val_loss: 0.1098 - val_r_square: 0.8839\n",
      "Epoch 91/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0542 - r_square: 0.9379 - val_loss: 0.2689 - val_r_square: 0.7115\n",
      "Epoch 92/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0757 - r_square: 0.9230 - val_loss: 0.1475 - val_r_square: 0.8515\n",
      "Epoch 93/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0609 - r_square: 0.9406 - val_loss: 0.1294 - val_r_square: 0.8604\n",
      "Epoch 94/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0627 - r_square: 0.9390 - val_loss: 0.1160 - val_r_square: 0.8754\n",
      "Epoch 95/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0674 - r_square: 0.9287 - val_loss: 0.2504 - val_r_square: 0.7243\n",
      "Epoch 96/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0801 - r_square: 0.9094 - val_loss: 0.2183 - val_r_square: 0.7627\n",
      "Epoch 97/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0840 - r_square: 0.9163 - val_loss: 0.1344 - val_r_square: 0.8572\n",
      "Epoch 98/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0578 - r_square: 0.9440 - val_loss: 0.1153 - val_r_square: 0.8775\n",
      "Epoch 99/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0515 - r_square: 0.9504 - val_loss: 0.1324 - val_r_square: 0.8598\n",
      "Epoch 100/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0591 - r_square: 0.9386 - val_loss: 0.1241 - val_r_square: 0.8646\n",
      "Epoch 101/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0545 - r_square: 0.9411 - val_loss: 0.1811 - val_r_square: 0.8156\n",
      "Epoch 102/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0618 - r_square: 0.9398 - val_loss: 0.1173 - val_r_square: 0.8731\n",
      "Epoch 103/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0568 - r_square: 0.9419 - val_loss: 0.1290 - val_r_square: 0.8677\n",
      "Epoch 104/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0620 - r_square: 0.9327 - val_loss: 0.4768 - val_r_square: 0.4997\n",
      "Epoch 105/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0768 - r_square: 0.9248 - val_loss: 0.1113 - val_r_square: 0.8795\n",
      "Epoch 106/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0526 - r_square: 0.9452 - val_loss: 0.1676 - val_r_square: 0.8231\n",
      "Epoch 107/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0610 - r_square: 0.9403 - val_loss: 0.1127 - val_r_square: 0.8806\n",
      "Epoch 108/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0488 - r_square: 0.9522 - val_loss: 0.1179 - val_r_square: 0.8763\n",
      "Epoch 109/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0536 - r_square: 0.9469 - val_loss: 0.1362 - val_r_square: 0.8574\n",
      "Epoch 110/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0715 - r_square: 0.9247 - val_loss: 0.1447 - val_r_square: 0.8458\n",
      "Epoch 111/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0523 - r_square: 0.9450 - val_loss: 0.1538 - val_r_square: 0.8324\n",
      "Epoch 112/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0627 - r_square: 0.9365 - val_loss: 0.1242 - val_r_square: 0.8646\n",
      "Epoch 113/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0484 - r_square: 0.9528 - val_loss: 0.1193 - val_r_square: 0.8765\n",
      "Epoch 114/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0541 - r_square: 0.9418 - val_loss: 0.1865 - val_r_square: 0.7988\n",
      "Epoch 115/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0570 - r_square: 0.9341 - val_loss: 0.2571 - val_r_square: 0.7394\n",
      "Epoch 116/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0704 - r_square: 0.9300 - val_loss: 0.1974 - val_r_square: 0.7827\n",
      "Epoch 117/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0553 - r_square: 0.9465 - val_loss: 0.1183 - val_r_square: 0.8728\n",
      "Epoch 118/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0481 - r_square: 0.9436 - val_loss: 0.1425 - val_r_square: 0.8550\n",
      "Epoch 119/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0549 - r_square: 0.9440 - val_loss: 0.1824 - val_r_square: 0.8022\n",
      "Epoch 120/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0505 - r_square: 0.9475 - val_loss: 0.1159 - val_r_square: 0.8773\n",
      "Epoch 121/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0494 - r_square: 0.9496 - val_loss: 0.1567 - val_r_square: 0.8315\n",
      "Epoch 122/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0518 - r_square: 0.9485 - val_loss: 0.1141 - val_r_square: 0.8743\n",
      "Epoch 123/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0466 - r_square: 0.9550 - val_loss: 0.1121 - val_r_square: 0.8805\n",
      "Epoch 124/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0464 - r_square: 0.9544 - val_loss: 0.1207 - val_r_square: 0.8684\n",
      "Epoch 125/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0480 - r_square: 0.9538 - val_loss: 0.1286 - val_r_square: 0.8612\n",
      "Epoch 126/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0459 - r_square: 0.9555 - val_loss: 0.1178 - val_r_square: 0.8724\n",
      "Epoch 127/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0492 - r_square: 0.9449 - val_loss: 0.1375 - val_r_square: 0.8559\n",
      "Epoch 128/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0524 - r_square: 0.9377 - val_loss: 0.6463 - val_r_square: 0.3026\n",
      "Epoch 129/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0919 - r_square: 0.9105 - val_loss: 0.1631 - val_r_square: 0.8180\n",
      "Epoch 130/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0551 - r_square: 0.9419 - val_loss: 0.1717 - val_r_square: 0.8098\n",
      "Epoch 131/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0551 - r_square: 0.9461 - val_loss: 0.1180 - val_r_square: 0.8724\n",
      "Epoch 132/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0516 - r_square: 0.9502 - val_loss: 0.1225 - val_r_square: 0.8668\n",
      "Epoch 133/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0499 - r_square: 0.9364 - val_loss: 0.2505 - val_r_square: 0.7443\n",
      "Epoch 134/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0622 - r_square: 0.9394 - val_loss: 0.1395 - val_r_square: 0.8482\n",
      "Epoch 135/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0485 - r_square: 0.9531 - val_loss: 0.1230 - val_r_square: 0.8644\n",
      "Epoch 136/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0511 - r_square: 0.9437 - val_loss: 0.1928 - val_r_square: 0.7842\n",
      "Epoch 137/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0518 - r_square: 0.9489 - val_loss: 0.1226 - val_r_square: 0.8677\n",
      "Epoch 138/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0589 - r_square: 0.9257 - val_loss: 2.2735 - val_r_square: -1.4093\n",
      "Epoch 139/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4942 - r_square: 0.5118 - val_loss: 0.1823 - val_r_square: 0.8101\n",
      "Epoch 140/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0955 - r_square: 0.9059 - val_loss: 0.1204 - val_r_square: 0.8779\n",
      "Epoch 141/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0669 - r_square: 0.9287 - val_loss: 0.3320 - val_r_square: 0.6537\n",
      "Epoch 142/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0973 - r_square: 0.9043 - val_loss: 0.1383 - val_r_square: 0.8533\n",
      "Epoch 143/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0570 - r_square: 0.9427 - val_loss: 0.1315 - val_r_square: 0.8654\n",
      "Epoch 144/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0536 - r_square: 0.9393 - val_loss: 0.1530 - val_r_square: 0.8324\n",
      "Epoch 145/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0519 - r_square: 0.9474 - val_loss: 0.1395 - val_r_square: 0.8486\n",
      "Epoch 146/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0481 - r_square: 0.9516 - val_loss: 0.1123 - val_r_square: 0.8794\n",
      "Epoch 147/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0472 - r_square: 0.9461 - val_loss: 0.1177 - val_r_square: 0.8769\n",
      "Epoch 148/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0460 - r_square: 0.9503 - val_loss: 0.1154 - val_r_square: 0.8799\n",
      "Epoch 149/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0494 - r_square: 0.9522 - val_loss: 0.1104 - val_r_square: 0.8802\n",
      "Epoch 150/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0446 - r_square: 0.9572 - val_loss: 0.1116 - val_r_square: 0.8804\n",
      "Epoch 151/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0425 - r_square: 0.9544 - val_loss: 0.1248 - val_r_square: 0.8710\n",
      "Epoch 152/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0460 - r_square: 0.9554 - val_loss: 0.1121 - val_r_square: 0.8818\n",
      "Epoch 153/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0450 - r_square: 0.9547 - val_loss: 0.1121 - val_r_square: 0.8779\n",
      "Epoch 154/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0421 - r_square: 0.9545 - val_loss: 0.1345 - val_r_square: 0.8528\n",
      "Epoch 155/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0457 - r_square: 0.9553 - val_loss: 0.1090 - val_r_square: 0.8827\n",
      "Epoch 156/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0432 - r_square: 0.9564 - val_loss: 0.1120 - val_r_square: 0.8780\n",
      "Epoch 157/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0558 - r_square: 0.9040 - val_loss: 1.8802 - val_r_square: -0.9534\n",
      "Epoch 158/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4953 - r_square: 0.5249 - val_loss: 0.1783 - val_r_square: 0.8202\n",
      "Epoch 159/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0912 - r_square: 0.9104 - val_loss: 0.1413 - val_r_square: 0.8527\n",
      "Epoch 160/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0660 - r_square: 0.9359 - val_loss: 0.1363 - val_r_square: 0.8578\n",
      "Epoch 161/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0605 - r_square: 0.9409 - val_loss: 0.1252 - val_r_square: 0.8669\n",
      "Epoch 162/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0569 - r_square: 0.9442 - val_loss: 0.1171 - val_r_square: 0.8753\n",
      "Epoch 163/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0605 - r_square: 0.8940 - val_loss: 0.2878 - val_r_square: 0.6911\n",
      "Epoch 164/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1075 - r_square: 0.8922 - val_loss: 0.1705 - val_r_square: 0.8147\n",
      "Epoch 165/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0610 - r_square: 0.9412 - val_loss: 0.1256 - val_r_square: 0.8630\n",
      "Epoch 166/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0528 - r_square: 0.9477 - val_loss: 0.1254 - val_r_square: 0.8679\n",
      "Epoch 167/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0477 - r_square: 0.9518 - val_loss: 0.1259 - val_r_square: 0.8649\n",
      "Epoch 168/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0466 - r_square: 0.9546 - val_loss: 0.1219 - val_r_square: 0.8680\n",
      "Epoch 169/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0473 - r_square: 0.9498 - val_loss: 0.2256 - val_r_square: 0.7578\n",
      "Epoch 170/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0520 - r_square: 0.9412 - val_loss: 0.1264 - val_r_square: 0.8638\n",
      "Epoch 171/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0588 - r_square: 0.9418 - val_loss: 0.1360 - val_r_square: 0.8560\n",
      "Epoch 172/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0520 - r_square: 0.9428 - val_loss: 0.2110 - val_r_square: 0.7718\n",
      "Epoch 173/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0512 - r_square: 0.9504 - val_loss: 0.1289 - val_r_square: 0.8603\n",
      "Epoch 174/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0459 - r_square: 0.9504 - val_loss: 0.1328 - val_r_square: 0.8549\n",
      "Epoch 175/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0492 - r_square: 0.9496 - val_loss: 0.1212 - val_r_square: 0.8702\n",
      "Epoch 176/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0410 - r_square: 0.9591 - val_loss: 0.1148 - val_r_square: 0.8762\n",
      "Epoch 177/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0430 - r_square: 0.9582 - val_loss: 0.1178 - val_r_square: 0.8713\n",
      "Epoch 178/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0405 - r_square: 0.9565 - val_loss: 0.1308 - val_r_square: 0.8544\n",
      "Epoch 179/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0475 - r_square: 0.9529 - val_loss: 0.1253 - val_r_square: 0.8622\n",
      "Epoch 180/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0439 - r_square: 0.9545 - val_loss: 0.1344 - val_r_square: 0.8560\n",
      "Epoch 181/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0540 - r_square: 0.9470 - val_loss: 0.1283 - val_r_square: 0.8601\n",
      "Epoch 182/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0457 - r_square: 0.9561 - val_loss: 0.1211 - val_r_square: 0.8656\n",
      "Epoch 183/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0421 - r_square: 0.9586 - val_loss: 0.1428 - val_r_square: 0.8454\n",
      "Epoch 184/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0423 - r_square: 0.9588 - val_loss: 0.1171 - val_r_square: 0.8713\n",
      "Epoch 185/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0387 - r_square: 0.9602 - val_loss: 0.1485 - val_r_square: 0.8383\n",
      "Epoch 186/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0461 - r_square: 0.9531 - val_loss: 0.1151 - val_r_square: 0.8734\n",
      "Epoch 187/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0393 - r_square: 0.9616 - val_loss: 0.1256 - val_r_square: 0.8619\n",
      "Epoch 188/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0400 - r_square: 0.9563 - val_loss: 0.1198 - val_r_square: 0.8721\n",
      "Epoch 189/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0440 - r_square: 0.9565 - val_loss: 0.1205 - val_r_square: 0.8706\n",
      "Epoch 190/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0386 - r_square: 0.9628 - val_loss: 0.1221 - val_r_square: 0.8663\n",
      "Epoch 191/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0505 - r_square: 0.9491 - val_loss: 0.1237 - val_r_square: 0.8635\n",
      "Epoch 192/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0423 - r_square: 0.9582 - val_loss: 0.1245 - val_r_square: 0.8648\n",
      "Epoch 193/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0436 - r_square: 0.9571 - val_loss: 0.1187 - val_r_square: 0.8711\n",
      "Epoch 194/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0392 - r_square: 0.9603 - val_loss: 0.1222 - val_r_square: 0.8655\n",
      "Epoch 195/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0422 - r_square: 0.9405 - val_loss: 0.3102 - val_r_square: 0.6700\n",
      "Epoch 196/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0805 - r_square: 0.9213 - val_loss: 0.1146 - val_r_square: 0.8782\n",
      "Epoch 197/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0387 - r_square: 0.9625 - val_loss: 0.1114 - val_r_square: 0.8841\n",
      "Epoch 198/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0437 - r_square: 0.9580 - val_loss: 0.1143 - val_r_square: 0.8768\n",
      "Epoch 199/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0384 - r_square: 0.9626 - val_loss: 0.1119 - val_r_square: 0.8785\n",
      "Epoch 200/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0390 - r_square: 0.9623 - val_loss: 0.1162 - val_r_square: 0.8723\n",
      "Epoch 201/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0355 - r_square: 0.9627 - val_loss: 0.1198 - val_r_square: 0.8692\n",
      "Epoch 202/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0385 - r_square: 0.9621 - val_loss: 0.1235 - val_r_square: 0.8644\n",
      "Epoch 203/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0396 - r_square: 0.9616 - val_loss: 0.1176 - val_r_square: 0.8733\n",
      "Epoch 204/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0386 - r_square: 0.9616 - val_loss: 0.1218 - val_r_square: 0.8702\n",
      "Epoch 205/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0336 - r_square: 0.9660 - val_loss: 0.1167 - val_r_square: 0.8739\n",
      "Epoch 206/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0407 - r_square: 0.9580 - val_loss: 0.1421 - val_r_square: 0.8446\n",
      "Epoch 207/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0446 - r_square: 0.9527 - val_loss: 0.1452 - val_r_square: 0.8487\n",
      "Epoch 208/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0433 - r_square: 0.9578 - val_loss: 0.1150 - val_r_square: 0.8758\n",
      "Epoch 209/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0380 - r_square: 0.9600 - val_loss: 0.1377 - val_r_square: 0.8488\n",
      "Epoch 210/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0435 - r_square: 0.9582 - val_loss: 0.1154 - val_r_square: 0.8754\n",
      "Epoch 211/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0380 - r_square: 0.9633 - val_loss: 0.1156 - val_r_square: 0.8735\n",
      "Epoch 212/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0360 - r_square: 0.9649 - val_loss: 0.1132 - val_r_square: 0.8775\n",
      "Epoch 213/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0366 - r_square: 0.9621 - val_loss: 0.1193 - val_r_square: 0.8709\n",
      "Epoch 214/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0365 - r_square: 0.9642 - val_loss: 0.1132 - val_r_square: 0.8782\n",
      "Epoch 215/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0344 - r_square: 0.9668 - val_loss: 0.1096 - val_r_square: 0.8819\n",
      "Epoch 216/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0345 - r_square: 0.9627 - val_loss: 0.1109 - val_r_square: 0.8832\n",
      "Epoch 217/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0380 - r_square: 0.9621 - val_loss: 0.1341 - val_r_square: 0.8596\n",
      "Epoch 218/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0377 - r_square: 0.9625 - val_loss: 0.1245 - val_r_square: 0.8668\n",
      "Epoch 219/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0384 - r_square: 0.9623 - val_loss: 0.1077 - val_r_square: 0.8850\n",
      "Epoch 220/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0335 - r_square: 0.9661 - val_loss: 0.1795 - val_r_square: 0.8057\n",
      "Epoch 221/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0413 - r_square: 0.9576 - val_loss: 0.1330 - val_r_square: 0.8568\n",
      "Epoch 222/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0520 - r_square: 0.9164 - val_loss: 0.8017 - val_r_square: 0.1225\n",
      "Epoch 223/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2966 - r_square: 0.7154 - val_loss: 0.1691 - val_r_square: 0.8151\n",
      "Epoch 224/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0789 - r_square: 0.9160 - val_loss: 0.1242 - val_r_square: 0.8636\n",
      "Epoch 225/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0645 - r_square: 0.9322 - val_loss: 0.1362 - val_r_square: 0.8583\n",
      "Epoch 226/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0528 - r_square: 0.9479 - val_loss: 0.1097 - val_r_square: 0.8814\n",
      "Epoch 227/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0421 - r_square: 0.9479 - val_loss: 0.1901 - val_r_square: 0.8116\n",
      "Epoch 228/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0533 - r_square: 0.9487 - val_loss: 0.1089 - val_r_square: 0.8835\n",
      "Epoch 229/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0400 - r_square: 0.9607 - val_loss: 0.1200 - val_r_square: 0.8704\n",
      "Epoch 230/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0381 - r_square: 0.9616 - val_loss: 0.1119 - val_r_square: 0.8801\n",
      "Epoch 231/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0383 - r_square: 0.9578 - val_loss: 0.1184 - val_r_square: 0.8764\n",
      "Epoch 232/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0388 - r_square: 0.9625 - val_loss: 0.1108 - val_r_square: 0.8805\n",
      "Epoch 233/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0400 - r_square: 0.9615 - val_loss: 0.1142 - val_r_square: 0.8777\n",
      "Epoch 234/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0393 - r_square: 0.9623 - val_loss: 0.1139 - val_r_square: 0.8782\n",
      "Epoch 235/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0366 - r_square: 0.9617 - val_loss: 0.3380 - val_r_square: 0.6431\n",
      "Epoch 236/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0716 - r_square: 0.9305 - val_loss: 0.1154 - val_r_square: 0.8770\n",
      "Epoch 237/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0389 - r_square: 0.9615 - val_loss: 0.1072 - val_r_square: 0.8840\n",
      "Epoch 238/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0374 - r_square: 0.9628 - val_loss: 0.1373 - val_r_square: 0.8590\n",
      "Epoch 239/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0394 - r_square: 0.9506 - val_loss: 0.2326 - val_r_square: 0.7646\n",
      "Epoch 240/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0559 - r_square: 0.9431 - val_loss: 0.1163 - val_r_square: 0.8745\n",
      "Epoch 241/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0389 - r_square: 0.9624 - val_loss: 0.1221 - val_r_square: 0.8670\n",
      "Epoch 242/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0330 - r_square: 0.9682 - val_loss: 0.1155 - val_r_square: 0.8774\n",
      "Epoch 243/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0323 - r_square: 0.9685 - val_loss: 0.1141 - val_r_square: 0.8774\n",
      "Epoch 244/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0360 - r_square: 0.9653 - val_loss: 0.1291 - val_r_square: 0.8598\n",
      "Epoch 245/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0352 - r_square: 0.9659 - val_loss: 0.1185 - val_r_square: 0.8729\n",
      "Epoch 246/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0360 - r_square: 0.9640 - val_loss: 0.1158 - val_r_square: 0.8754\n",
      "Epoch 247/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0338 - r_square: 0.9674 - val_loss: 0.1140 - val_r_square: 0.8776\n",
      "Epoch 248/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0359 - r_square: 0.9545 - val_loss: 0.2780 - val_r_square: 0.7002\n",
      "Epoch 249/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0772 - r_square: 0.9252 - val_loss: 0.1287 - val_r_square: 0.8658\n",
      "Epoch 250/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0416 - r_square: 0.9598 - val_loss: 0.1193 - val_r_square: 0.8748\n",
      "Epoch 251/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0368 - r_square: 0.9551 - val_loss: 0.2672 - val_r_square: 0.7326\n",
      "Epoch 252/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0714 - r_square: 0.9294 - val_loss: 0.1233 - val_r_square: 0.8707\n",
      "Epoch 253/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0386 - r_square: 0.9611 - val_loss: 0.1172 - val_r_square: 0.8784\n",
      "Epoch 254/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0412 - r_square: 0.9596 - val_loss: 0.1180 - val_r_square: 0.8747\n",
      "Epoch 255/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0321 - r_square: 0.9659 - val_loss: 0.1204 - val_r_square: 0.8703\n",
      "Epoch 256/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0342 - r_square: 0.9668 - val_loss: 0.1153 - val_r_square: 0.8778\n",
      "Epoch 257/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0334 - r_square: 0.9638 - val_loss: 0.1388 - val_r_square: 0.8532\n",
      "Epoch 258/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0383 - r_square: 0.9594 - val_loss: 0.1287 - val_r_square: 0.8591\n",
      "Epoch 259/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0369 - r_square: 0.9634 - val_loss: 0.1136 - val_r_square: 0.8791\n",
      "Epoch 260/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0406 - r_square: 0.9477 - val_loss: 0.2882 - val_r_square: 0.6889\n",
      "Epoch 261/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0861 - r_square: 0.9172 - val_loss: 0.1212 - val_r_square: 0.8702\n",
      "Epoch 262/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0385 - r_square: 0.9492 - val_loss: 0.1743 - val_r_square: 0.8265\n",
      "Epoch 263/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0505 - r_square: 0.9513 - val_loss: 0.1188 - val_r_square: 0.8729\n",
      "Epoch 264/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0362 - r_square: 0.9585 - val_loss: 0.1220 - val_r_square: 0.8714\n",
      "Epoch 265/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0374 - r_square: 0.9630 - val_loss: 0.1143 - val_r_square: 0.8766\n",
      "Epoch 266/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0352 - r_square: 0.9629 - val_loss: 0.1212 - val_r_square: 0.8692\n",
      "Epoch 267/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0328 - r_square: 0.9657 - val_loss: 0.1256 - val_r_square: 0.8670\n",
      "Epoch 268/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0321 - r_square: 0.9688 - val_loss: 0.1215 - val_r_square: 0.8696\n",
      "Epoch 269/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0296 - r_square: 0.9712 - val_loss: 0.1178 - val_r_square: 0.8741\n",
      "Epoch 270/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0305 - r_square: 0.9698 - val_loss: 0.1200 - val_r_square: 0.8725\n",
      "Epoch 271/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0357 - r_square: 0.9646 - val_loss: 0.1315 - val_r_square: 0.8617\n",
      "Epoch 272/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0360 - r_square: 0.9615 - val_loss: 0.3167 - val_r_square: 0.6650\n",
      "Epoch 273/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0505 - r_square: 0.9516 - val_loss: 0.1151 - val_r_square: 0.8783\n",
      "Epoch 274/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0343 - r_square: 0.9665 - val_loss: 0.1163 - val_r_square: 0.8765\n",
      "Epoch 275/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0362 - r_square: 0.9649 - val_loss: 0.1212 - val_r_square: 0.8699\n",
      "Epoch 276/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0436 - r_square: 0.9066 - val_loss: 0.7951 - val_r_square: 0.1713\n",
      "Epoch 277/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5031 - r_square: 0.4972 - val_loss: 0.2766 - val_r_square: 0.7136\n",
      "Epoch 278/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1335 - r_square: 0.8324 - val_loss: 0.2924 - val_r_square: 0.6997\n",
      "Epoch 279/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1468 - r_square: 0.8436 - val_loss: 0.1699 - val_r_square: 0.8282\n",
      "Epoch 280/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0910 - r_square: 0.9099 - val_loss: 0.1368 - val_r_square: 0.8617\n",
      "Epoch 281/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0615 - r_square: 0.9397 - val_loss: 0.1193 - val_r_square: 0.8790\n",
      "Epoch 282/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0534 - r_square: 0.9471 - val_loss: 0.1193 - val_r_square: 0.8754\n",
      "Epoch 283/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0492 - r_square: 0.9517 - val_loss: 0.1143 - val_r_square: 0.8825\n",
      "Epoch 284/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0472 - r_square: 0.9541 - val_loss: 0.1246 - val_r_square: 0.8714\n",
      "Epoch 285/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0411 - r_square: 0.9498 - val_loss: 0.1337 - val_r_square: 0.8619\n",
      "Epoch 286/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0449 - r_square: 0.9536 - val_loss: 0.1166 - val_r_square: 0.8772\n",
      "Epoch 287/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0391 - r_square: 0.9619 - val_loss: 0.1113 - val_r_square: 0.8810\n",
      "Epoch 288/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0381 - r_square: 0.9630 - val_loss: 0.1084 - val_r_square: 0.8861\n",
      "Epoch 289/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0357 - r_square: 0.9645 - val_loss: 0.1097 - val_r_square: 0.8841\n",
      "Epoch 290/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0347 - r_square: 0.9662 - val_loss: 0.1105 - val_r_square: 0.8827\n",
      "Epoch 291/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0331 - r_square: 0.9657 - val_loss: 0.1044 - val_r_square: 0.8886\n",
      "Epoch 292/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0369 - r_square: 0.9606 - val_loss: 0.1102 - val_r_square: 0.8836\n",
      "Epoch 293/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0344 - r_square: 0.9655 - val_loss: 0.1092 - val_r_square: 0.8815\n",
      "Epoch 294/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0344 - r_square: 0.9505 - val_loss: 0.1526 - val_r_square: 0.8315\n",
      "Epoch 295/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0423 - r_square: 0.9590 - val_loss: 0.1132 - val_r_square: 0.8784\n",
      "Epoch 296/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0410 - r_square: 0.9597 - val_loss: 0.1115 - val_r_square: 0.8815\n",
      "Epoch 297/300\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0354 - r_square: 0.9652 - val_loss: 0.1213 - val_r_square: 0.8683\n",
      "Epoch 298/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0371 - r_square: 0.9636 - val_loss: 0.1120 - val_r_square: 0.8792\n",
      "Epoch 299/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0340 - r_square: 0.9619 - val_loss: 0.1443 - val_r_square: 0.8505\n",
      "Epoch 300/300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0438 - r_square: 0.9577 - val_loss: 0.1154 - val_r_square: 0.8770\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=300, validation_split=0.2, batch_size=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse metric\n",
    "epochs_from_end = 100\n",
    "epoch_x_values = list(range(len(history.history['loss'])-epochs_from_end, len(history.history['loss'])))\n",
    "plt.plot(epoch_x_values, history.history['loss'][-epochs_from_end:])\n",
    "plt.plot(epoch_x_values, history.history['val_loss'][-epochs_from_end:])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot r^2 metric\n",
    "epochs_from_end = 100\n",
    "epoch_x_values = list(range(len(history.history['r_square'])-epochs_from_end, len(history.history['r_square'])))\n",
    "plt.plot(epoch_x_values, history.history['r_square'][-epochs_from_end:])\n",
    "plt.plot(epoch_x_values, history.history['val_r_square'][-epochs_from_end:])\n",
    "plt.title('model r_square')\n",
    "plt.ylabel('r_square')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some info about model and training to save for later reference\n",
    "print(\"StandardScaler\\n\")\n",
    "print(model.summary(), \"\\n\")\n",
    "print(history.params, \"\\n\")\n",
    "print(f\"mean train loss last 10 epochs: {np.mean(history.history['loss'][-10:])}\")\n",
    "print(f\"mean val loss last 10 epochs: {np.mean(history.history['val_loss'][-10:])}\")\n",
    "print(f\"mean train r^2 last 10 epochs: {np.mean(history.history['r_square'][-10:])}\")\n",
    "print(f\"mean val r^2 last 10 epochs: {np.mean(history.history['val_r_square'][-10:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new model on all traindata\n",
    "pred_model = Sequential([ \n",
    "                   Dense(200, activation=\"relu\", input_shape=(sample_vector_length,)),\n",
    "                   Dense(100, activation=\"relu\"),\n",
    "                   Dense(100, activation=\"relu\"),\n",
    "                   Dense(1)])\n",
    "pred_model.compile(optimizer=tensorflow.keras.optimizers.Nadam(),\n",
    "             loss=r_square_loss,\n",
    "             metrics=[r_square])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.4158 - r_square: -4.4021\n",
      "Epoch 2/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3763 - r_square: -0.3684\n",
      "Epoch 3/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5727 - r_square: 0.4292\n",
      "Epoch 4/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4981 - r_square: 0.5026\n",
      "Epoch 5/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5119 - r_square: 0.4899\n",
      "Epoch 6/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4643 - r_square: 0.5373\n",
      "Epoch 7/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4455 - r_square: 0.5540\n",
      "Epoch 8/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4082 - r_square: 0.5911\n",
      "Epoch 9/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4120 - r_square: 0.5828\n",
      "Epoch 10/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3649 - r_square: 0.6361\n",
      "Epoch 11/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3694 - r_square: 0.6332\n",
      "Epoch 12/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3533 - r_square: 0.6471\n",
      "Epoch 13/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3495 - r_square: 0.6475\n",
      "Epoch 14/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3159 - r_square: 0.6859\n",
      "Epoch 15/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2832 - r_square: 0.7172\n",
      "Epoch 16/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2710 - r_square: 0.7302\n",
      "Epoch 17/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2470 - r_square: 0.7541\n",
      "Epoch 18/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2273 - r_square: 0.7721\n",
      "Epoch 19/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2222 - r_square: 0.7786\n",
      "Epoch 20/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1731 - r_square: 0.8265\n",
      "Epoch 21/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1809 - r_square: 0.8189\n",
      "Epoch 22/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1560 - r_square: 0.8429\n",
      "Epoch 23/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1404 - r_square: 0.8601\n",
      "Epoch 24/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1296 - r_square: 0.8701\n",
      "Epoch 25/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1257 - r_square: 0.8740\n",
      "Epoch 26/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1250 - r_square: 0.8750\n",
      "Epoch 27/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1291 - r_square: 0.8710\n",
      "Epoch 28/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1152 - r_square: 0.8843\n",
      "Epoch 29/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1075 - r_square: 0.8900\n",
      "Epoch 30/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1010 - r_square: 0.8984\n",
      "Epoch 31/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1087 - r_square: 0.8917\n",
      "Epoch 32/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1053 - r_square: 0.8950\n",
      "Epoch 33/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0998 - r_square: 0.9005\n",
      "Epoch 34/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1099 - r_square: 0.8898\n",
      "Epoch 35/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0916 - r_square: 0.9083\n",
      "Epoch 36/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1021 - r_square: 0.8976\n",
      "Epoch 37/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1047 - r_square: 0.8942\n",
      "Epoch 38/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0928 - r_square: 0.9071\n",
      "Epoch 39/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0934 - r_square: 0.9072\n",
      "Epoch 40/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0821 - r_square: 0.9166\n",
      "Epoch 41/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0867 - r_square: 0.9134\n",
      "Epoch 42/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0863 - r_square: 0.9141\n",
      "Epoch 43/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0884 - r_square: 0.9118\n",
      "Epoch 44/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0848 - r_square: 0.9155\n",
      "Epoch 45/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0754 - r_square: 0.9250\n",
      "Epoch 46/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0854 - r_square: 0.9138\n",
      "Epoch 47/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0835 - r_square: 0.9170\n",
      "Epoch 48/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0828 - r_square: 0.9174\n",
      "Epoch 49/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0815 - r_square: 0.9184\n",
      "Epoch 50/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0789 - r_square: 0.9212\n",
      "Epoch 51/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0713 - r_square: 0.9287\n",
      "Epoch 52/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0737 - r_square: 0.9263\n",
      "Epoch 53/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0662 - r_square: 0.9334\n",
      "Epoch 54/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0753 - r_square: 0.9248\n",
      "Epoch 55/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0773 - r_square: 0.9231\n",
      "Epoch 56/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0753 - r_square: 0.9245\n",
      "Epoch 57/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0711 - r_square: 0.9289\n",
      "Epoch 58/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0690 - r_square: 0.9313\n",
      "Epoch 59/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0673 - r_square: 0.9330\n",
      "Epoch 60/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0706 - r_square: 0.9299\n",
      "Epoch 61/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0967 - r_square: 0.9041\n",
      "Epoch 62/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0725 - r_square: 0.9272\n",
      "Epoch 63/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0701 - r_square: 0.9302\n",
      "Epoch 64/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0703 - r_square: 0.9299\n",
      "Epoch 65/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0723 - r_square: 0.9280\n",
      "Epoch 66/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0645 - r_square: 0.9358\n",
      "Epoch 67/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0633 - r_square: 0.9367\n",
      "Epoch 68/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0676 - r_square: 0.9329\n",
      "Epoch 69/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0614 - r_square: 0.9385\n",
      "Epoch 70/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0633 - r_square: 0.9366\n",
      "Epoch 71/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0609 - r_square: 0.9390\n",
      "Epoch 72/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0688 - r_square: 0.9314\n",
      "Epoch 73/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0613 - r_square: 0.9386\n",
      "Epoch 74/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0644 - r_square: 0.9359\n",
      "Epoch 75/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0574 - r_square: 0.9428\n",
      "Epoch 76/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0576 - r_square: 0.9425\n",
      "Epoch 77/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0702 - r_square: 0.9301\n",
      "Epoch 78/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0615 - r_square: 0.9382\n",
      "Epoch 79/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0638 - r_square: 0.9364\n",
      "Epoch 80/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0573 - r_square: 0.9430\n",
      "Epoch 81/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0611 - r_square: 0.9386\n",
      "Epoch 82/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0558 - r_square: 0.9442\n",
      "Epoch 83/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0564 - r_square: 0.9435\n",
      "Epoch 84/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0555 - r_square: 0.9447\n",
      "Epoch 85/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0604 - r_square: 0.9400\n",
      "Epoch 86/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0566 - r_square: 0.9431\n",
      "Epoch 87/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0565 - r_square: 0.9434\n",
      "Epoch 88/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0644 - r_square: 0.9359\n",
      "Epoch 89/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0548 - r_square: 0.9455\n",
      "Epoch 90/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0587 - r_square: 0.9416\n",
      "Epoch 91/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0656 - r_square: 0.9347\n",
      "Epoch 92/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0579 - r_square: 0.9412\n",
      "Epoch 93/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0597 - r_square: 0.9403\n",
      "Epoch 94/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0503 - r_square: 0.9496\n",
      "Epoch 95/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0503 - r_square: 0.9499\n",
      "Epoch 96/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0524 - r_square: 0.9479\n",
      "Epoch 97/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0520 - r_square: 0.9483\n",
      "Epoch 98/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0493 - r_square: 0.9506\n",
      "Epoch 99/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0520 - r_square: 0.9479\n",
      "Epoch 100/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0541 - r_square: 0.9462\n",
      "Epoch 101/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0468 - r_square: 0.9535\n",
      "Epoch 102/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0490 - r_square: 0.9505\n",
      "Epoch 103/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0629 - r_square: 0.9372\n",
      "Epoch 104/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0568 - r_square: 0.9435\n",
      "Epoch 105/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0554 - r_square: 0.9445\n",
      "Epoch 106/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0474 - r_square: 0.9527\n",
      "Epoch 107/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0462 - r_square: 0.9541\n",
      "Epoch 108/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0468 - r_square: 0.9533\n",
      "Epoch 109/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0522 - r_square: 0.9478\n",
      "Epoch 110/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0508 - r_square: 0.9496\n",
      "Epoch 111/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0503 - r_square: 0.9502\n",
      "Epoch 112/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0473 - r_square: 0.9523\n",
      "Epoch 113/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0493 - r_square: 0.9507\n",
      "Epoch 114/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0478 - r_square: 0.9523\n",
      "Epoch 115/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0480 - r_square: 0.9520\n",
      "Epoch 116/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0459 - r_square: 0.9542\n",
      "Epoch 117/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0466 - r_square: 0.9532\n",
      "Epoch 118/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0498 - r_square: 0.9502\n",
      "Epoch 119/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0473 - r_square: 0.9530\n",
      "Epoch 120/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0475 - r_square: 0.9527\n",
      "Epoch 121/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0527 - r_square: 0.9473\n",
      "Epoch 122/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0434 - r_square: 0.9569\n",
      "Epoch 123/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0535 - r_square: 0.9463\n",
      "Epoch 124/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0448 - r_square: 0.9555\n",
      "Epoch 125/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0475 - r_square: 0.9523\n",
      "Epoch 126/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0443 - r_square: 0.9557\n",
      "Epoch 127/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0423 - r_square: 0.9577\n",
      "Epoch 128/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0448 - r_square: 0.9554\n",
      "Epoch 129/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0417 - r_square: 0.9564\n",
      "Epoch 130/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0503 - r_square: 0.9500\n",
      "Epoch 131/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0425 - r_square: 0.9576\n",
      "Epoch 132/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0416 - r_square: 0.9586\n",
      "Epoch 133/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0430 - r_square: 0.9571\n",
      "Epoch 134/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0489 - r_square: 0.9511\n",
      "Epoch 135/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0491 - r_square: 0.9511\n",
      "Epoch 136/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0446 - r_square: 0.9554\n",
      "Epoch 137/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0428 - r_square: 0.9572\n",
      "Epoch 138/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0427 - r_square: 0.9560\n",
      "Epoch 139/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0451 - r_square: 0.9533\n",
      "Epoch 140/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0394 - r_square: 0.9607\n",
      "Epoch 141/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0484 - r_square: 0.9519\n",
      "Epoch 142/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0488 - r_square: 0.9514\n",
      "Epoch 143/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0432 - r_square: 0.9562\n",
      "Epoch 144/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0412 - r_square: 0.9590\n",
      "Epoch 145/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0377 - r_square: 0.9621\n",
      "Epoch 146/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0374 - r_square: 0.9622\n",
      "Epoch 147/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0374 - r_square: 0.9629\n",
      "Epoch 148/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0407 - r_square: 0.9595\n",
      "Epoch 149/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0376 - r_square: 0.9621\n",
      "Epoch 150/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0478 - r_square: 0.9524\n",
      "Epoch 151/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0459 - r_square: 0.9544\n",
      "Epoch 152/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0357 - r_square: 0.9644\n",
      "Epoch 153/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0420 - r_square: 0.9577\n",
      "Epoch 154/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0453 - r_square: 0.9548\n",
      "Epoch 155/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0355 - r_square: 0.9646\n",
      "Epoch 156/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0447 - r_square: 0.9556\n",
      "Epoch 157/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0394 - r_square: 0.9608\n",
      "Epoch 158/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0357 - r_square: 0.9646\n",
      "Epoch 159/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0428 - r_square: 0.9576\n",
      "Epoch 160/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0356 - r_square: 0.9645\n",
      "Epoch 161/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0369 - r_square: 0.9628\n",
      "Epoch 162/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0427 - r_square: 0.9575\n",
      "Epoch 163/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0412 - r_square: 0.9591\n",
      "Epoch 164/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0371 - r_square: 0.9627\n",
      "Epoch 165/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0350 - r_square: 0.9648\n",
      "Epoch 166/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0444 - r_square: 0.9559\n",
      "Epoch 167/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0384 - r_square: 0.9608\n",
      "Epoch 168/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0455 - r_square: 0.9545\n",
      "Epoch 169/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0464 - r_square: 0.9539\n",
      "Epoch 170/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0379 - r_square: 0.9621\n",
      "Epoch 171/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0314 - r_square: 0.9684\n",
      "Epoch 172/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0334 - r_square: 0.9663\n",
      "Epoch 173/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0373 - r_square: 0.9629\n",
      "Epoch 174/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0345 - r_square: 0.9657\n",
      "Epoch 175/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0324 - r_square: 0.9678\n",
      "Epoch 176/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0415 - r_square: 0.9585\n",
      "Epoch 177/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0394 - r_square: 0.9605\n",
      "Epoch 178/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0341 - r_square: 0.9659\n",
      "Epoch 179/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0324 - r_square: 0.9678\n",
      "Epoch 180/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0307 - r_square: 0.9693\n",
      "Epoch 181/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0330 - r_square: 0.9672\n",
      "Epoch 182/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0333 - r_square: 0.9666\n",
      "Epoch 183/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0328 - r_square: 0.9671\n",
      "Epoch 184/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0326 - r_square: 0.9675\n",
      "Epoch 185/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0345 - r_square: 0.9656\n",
      "Epoch 186/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0330 - r_square: 0.9664\n",
      "Epoch 187/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0346 - r_square: 0.9651\n",
      "Epoch 188/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0333 - r_square: 0.9668\n",
      "Epoch 189/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0350 - r_square: 0.9652\n",
      "Epoch 190/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0317 - r_square: 0.9668\n",
      "Epoch 191/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0319 - r_square: 0.9683\n",
      "Epoch 192/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0326 - r_square: 0.9670\n",
      "Epoch 193/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0354 - r_square: 0.9646\n",
      "Epoch 194/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0368 - r_square: 0.9634\n",
      "Epoch 195/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0385 - r_square: 0.9616\n",
      "Epoch 196/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0329 - r_square: 0.9648\n",
      "Epoch 197/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0352 - r_square: 0.9649\n",
      "Epoch 198/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0342 - r_square: 0.9658\n",
      "Epoch 199/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0409 - r_square: 0.9588\n",
      "Epoch 200/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0388 - r_square: 0.9614\n",
      "Epoch 201/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0320 - r_square: 0.9678\n",
      "Epoch 202/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0367 - r_square: 0.9634\n",
      "Epoch 203/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0315 - r_square: 0.9684\n",
      "Epoch 204/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0324 - r_square: 0.9678\n",
      "Epoch 205/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0311 - r_square: 0.9689\n",
      "Epoch 206/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0336 - r_square: 0.9664\n",
      "Epoch 207/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0302 - r_square: 0.9696\n",
      "Epoch 208/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0304 - r_square: 0.9697\n",
      "Epoch 209/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0313 - r_square: 0.9687\n",
      "Epoch 210/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0283 - r_square: 0.9717\n",
      "Epoch 211/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0397 - r_square: 0.9605\n",
      "Epoch 212/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0324 - r_square: 0.9676\n",
      "Epoch 213/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0291 - r_square: 0.9710\n",
      "Epoch 214/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0272 - r_square: 0.9725\n",
      "Epoch 215/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0334 - r_square: 0.9668\n",
      "Epoch 216/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0351 - r_square: 0.9651\n",
      "Epoch 217/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0296 - r_square: 0.9704\n",
      "Epoch 218/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0313 - r_square: 0.9678\n",
      "Epoch 219/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0348 - r_square: 0.9649\n",
      "Epoch 220/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0289 - r_square: 0.9712\n",
      "Epoch 221/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0316 - r_square: 0.9686\n",
      "Epoch 222/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0318 - r_square: 0.9683\n",
      "Epoch 223/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0313 - r_square: 0.9687\n",
      "Epoch 224/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0280 - r_square: 0.9718\n",
      "Epoch 225/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0302 - r_square: 0.9699\n",
      "Epoch 226/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0285 - r_square: 0.9713\n",
      "Epoch 227/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0309 - r_square: 0.9689\n",
      "Epoch 228/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0323 - r_square: 0.9673\n",
      "Epoch 229/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0280 - r_square: 0.9721\n",
      "Epoch 230/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0306 - r_square: 0.9692\n",
      "Epoch 231/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0355 - r_square: 0.9627\n",
      "Epoch 232/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0335 - r_square: 0.9662\n",
      "Epoch 233/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0281 - r_square: 0.9719\n",
      "Epoch 234/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0285 - r_square: 0.9716\n",
      "Epoch 235/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0286 - r_square: 0.9714\n",
      "Epoch 236/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0261 - r_square: 0.9741\n",
      "Epoch 237/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0293 - r_square: 0.9708\n",
      "Epoch 238/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0297 - r_square: 0.9704\n",
      "Epoch 239/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0257 - r_square: 0.9734\n",
      "Epoch 240/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0284 - r_square: 0.9713\n",
      "Epoch 241/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0290 - r_square: 0.9711\n",
      "Epoch 242/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0304 - r_square: 0.9669\n",
      "Epoch 243/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0363 - r_square: 0.9640\n",
      "Epoch 244/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0280 - r_square: 0.9720\n",
      "Epoch 245/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0263 - r_square: 0.9737\n",
      "Epoch 246/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0292 - r_square: 0.9709\n",
      "Epoch 247/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0310 - r_square: 0.9693\n",
      "Epoch 248/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0327 - r_square: 0.9667\n",
      "Epoch 249/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0332 - r_square: 0.9668\n",
      "Epoch 250/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0272 - r_square: 0.9730\n",
      "Epoch 251/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0277 - r_square: 0.9725\n",
      "Epoch 252/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0265 - r_square: 0.9736\n",
      "Epoch 253/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0274 - r_square: 0.9727\n",
      "Epoch 254/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0278 - r_square: 0.9716\n",
      "Epoch 255/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0316 - r_square: 0.9685\n",
      "Epoch 256/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0401 - r_square: 0.9600\n",
      "Epoch 257/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0317 - r_square: 0.9684\n",
      "Epoch 258/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0278 - r_square: 0.9720\n",
      "Epoch 259/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0261 - r_square: 0.9726\n",
      "Epoch 260/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0282 - r_square: 0.9718\n",
      "Epoch 261/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0288 - r_square: 0.9714\n",
      "Epoch 262/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0242 - r_square: 0.9756\n",
      "Epoch 263/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0324 - r_square: 0.9678\n",
      "Epoch 264/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0294 - r_square: 0.9708\n",
      "Epoch 265/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0262 - r_square: 0.9738\n",
      "Epoch 266/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0270 - r_square: 0.9732\n",
      "Epoch 267/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0259 - r_square: 0.9740\n",
      "Epoch 268/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0284 - r_square: 0.9696\n",
      "Epoch 269/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0264 - r_square: 0.9734\n",
      "Epoch 270/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0231 - r_square: 0.9768\n",
      "Epoch 271/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0264 - r_square: 0.9738\n",
      "Epoch 272/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0247 - r_square: 0.9750\n",
      "Epoch 273/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0278 - r_square: 0.9722\n",
      "Epoch 274/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0264 - r_square: 0.9734\n",
      "Epoch 275/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0243 - r_square: 0.9756\n",
      "Epoch 276/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0296 - r_square: 0.9706\n",
      "Epoch 277/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0234 - r_square: 0.9765\n",
      "Epoch 278/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0248 - r_square: 0.9752\n",
      "Epoch 279/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0336 - r_square: 0.9656\n",
      "Epoch 280/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0457 - r_square: 0.9516\n",
      "Epoch 281/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0304 - r_square: 0.9697\n",
      "Epoch 282/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0292 - r_square: 0.9707\n",
      "Epoch 283/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0264 - r_square: 0.9737\n",
      "Epoch 284/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0257 - r_square: 0.9746\n",
      "Epoch 285/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0283 - r_square: 0.9719\n",
      "Epoch 286/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0308 - r_square: 0.9692\n",
      "Epoch 287/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0252 - r_square: 0.9749\n",
      "Epoch 288/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0246 - r_square: 0.9754\n",
      "Epoch 289/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0225 - r_square: 0.9774\n",
      "Epoch 290/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0303 - r_square: 0.9698\n",
      "Epoch 291/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0292 - r_square: 0.9708\n",
      "Epoch 292/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0239 - r_square: 0.9762\n",
      "Epoch 293/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0234 - r_square: 0.9767\n",
      "Epoch 294/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0212 - r_square: 0.9789\n",
      "Epoch 295/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0255 - r_square: 0.9747\n",
      "Epoch 296/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0280 - r_square: 0.9720\n",
      "Epoch 297/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0237 - r_square: 0.9765\n",
      "Epoch 298/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0242 - r_square: 0.9760\n",
      "Epoch 299/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0268 - r_square: 0.9732\n",
      "Epoch 300/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0262 - r_square: 0.9740\n"
     ]
    }
   ],
   "source": [
    "pred_history = pred_model.fit(x_train, y_train, epochs=300, batch_size=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on test data\n",
    "y_pred = pred_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction to submission format\n",
    "dfscore = pd.DataFrame(y_pred)\n",
    "ID = np.arange(0, len(dfscore), dtype=np.int64)\n",
    "dfID = pd.DataFrame(ID)\n",
    "dfscore.columns = [\"Predicted\"]\n",
    "dfID.columns = [\"Id\"]\n",
    "final_df = pd.concat([dfID, dfscore], axis=1)\n",
    "final_df.to_csv(\"Julius&Markus_comp1_ver1.10.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardscaler\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 200)               1800      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 32,101\n",
      "Trainable params: 32,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "{'verbose': 1, 'epochs': 300, 'steps': 23} \n",
      "\n",
      "mean train loss last 10 epochs: 0.037236590310931204\n",
      "mean train r^2 last 10 epochs: 0.9748851358890533\n"
     ]
    }
   ],
   "source": [
    "# show some info about model and training to save for later reference\n",
    "print(\"standardscaler\\n\")\n",
    "print(pred_model.summary(), \"\\n\")\n",
    "print(pred_history.params, \"\\n\")\n",
    "print(f\"mean train loss last 10 epochs: {np.mean(history.history['loss'][-10:])}\")\n",
    "print(f\"mean train r^2 last 10 epochs: {np.mean(pred_history.history['r_square'][-10:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
